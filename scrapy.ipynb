{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "876e4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mannan\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mannan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mannan\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00f34b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "BASE_URL = \"https://www.daiict.ac.in\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "FACULTY_PAGES = {\n",
    "    \"regular\": \"https://www.daiict.ac.in/faculty\",\n",
    "    \"adjunct\": \"https://www.daiict.ac.in/adjunct-faculty\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "232a9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_section_by_heading(soup, heading_text):\n",
    "    heading = soup.find(\n",
    "        \"h2\",\n",
    "        class_=\"rit-titl\",\n",
    "        string=lambda x: x and heading_text.lower() in x.lower()\n",
    "    )\n",
    "\n",
    "    if not heading:\n",
    "        return \"\"\n",
    "\n",
    "    content_div = heading.find_parent(\"div\").find_next_sibling(\"div\")\n",
    "    if not content_div:\n",
    "        return \"\"\n",
    "\n",
    "    ul = content_div.find(\"ul\")\n",
    "    if ul:\n",
    "        return [li.get_text(strip=True) for li in ul.find_all(\"li\")]\n",
    "\n",
    "    return content_div.get_text(\" \", strip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f812bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping regular faculty...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:20<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping adjunct faculty...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:07<00:00,  3.62it/s]\n"
     ]
    }
   ],
   "source": [
    "all_faculty_data = []\n",
    "\n",
    "for faculty_type, list_url in FACULTY_PAGES.items():\n",
    "    print(f\"\\nScraping {faculty_type} faculty...\")\n",
    "\n",
    "    response = requests.get(list_url, headers=HEADERS, timeout=15)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    faculty_cards = soup.select(\"div.facultyDetails\")\n",
    "\n",
    "    for card in tqdm(faculty_cards):\n",
    "        name_tag = card.select_one(\"h3 a\")\n",
    "        photo_tag = card.select_one(\".facultyPhoto img\")\n",
    "        edu_tag = card.select_one(\".facultyEducation\")\n",
    "        email_tag = card.select_one(\".facultyemail\")\n",
    "        area_tag = card.select_one(\".areaSpecialization\")\n",
    "\n",
    "        profile_url = urljoin(BASE_URL, name_tag[\"href\"]) if name_tag else \"\"\n",
    "\n",
    "        faculty_record = {\n",
    "            \"faculty_type\": faculty_type,\n",
    "            \"name\": name_tag.get_text(strip=True) if name_tag else \"\",\n",
    "            \"profile_url\": profile_url,\n",
    "            \"photo_url\": urljoin(BASE_URL, photo_tag[\"src\"]) if photo_tag else \"\",\n",
    "            \"education\": edu_tag.get_text(strip=True) if edu_tag else \"\",\n",
    "            \"email\": email_tag.get_text(strip=True) if email_tag else \"\",\n",
    "            \"area_specialization_short\": area_tag.get_text(strip=True) if area_tag else \"\"\n",
    "        }\n",
    "\n",
    "        if profile_url:\n",
    "            res = requests.get(profile_url, headers=HEADERS, timeout=15)\n",
    "            prof_soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "            bio_div = prof_soup.select_one(\"div.about\")\n",
    "            faculty_record[\"biography\"] = (\n",
    "                bio_div.get_text(\" \", strip=True) if bio_div else \"\"\n",
    "            )\n",
    "\n",
    "            faculty_record[\"specialisation\"] = extract_section_by_heading(prof_soup, \"Specialization\")\n",
    "            faculty_record[\"teaching\"] = extract_section_by_heading(prof_soup, \"Teaching\")\n",
    "            faculty_record[\"research\"] = extract_section_by_heading(prof_soup, \"Research\")\n",
    "            faculty_record[\"publications\"] = extract_section_by_heading(prof_soup, \"Publications\")\n",
    "\n",
    "        all_faculty_data.append(faculty_record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61e34f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_distinguished_faculty():\n",
    "    url = \"https://www.daiict.ac.in/distinguished-professor\"\n",
    "    res = requests.get(url, headers=HEADERS, timeout=15)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    records = []\n",
    "\n",
    "    cards = soup.select(\"div.facultyInformation li div.facultyDetails\")\n",
    "\n",
    "    for card in cards:\n",
    "        area = card.select_one(\"div.areaSpecialization p\")\n",
    "\n",
    "        records.append({\n",
    "            \"faculty_type\": \"distinguished\",\n",
    "            \"name\": \"Not Available\",\n",
    "            \"profile_url\": \"\",\n",
    "            \"photo_url\": \"\",\n",
    "            \"education\": \"\",\n",
    "            \"email\": \"\",\n",
    "            \"area_specialization_short\": area.get_text(\" \", strip=True) if area else \"\",\n",
    "            \"biography\": \"\",\n",
    "            \"specialisation\": \"\",\n",
    "            \"teaching\": \"\",\n",
    "            \"research\": \"\",\n",
    "            \"publications\": \"\"\n",
    "        })\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c0ae13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinguished faculty added: 1\n"
     ]
    }
   ],
   "source": [
    "distinguished_data = scrape_distinguished_faculty()\n",
    "all_faculty_data.extend(distinguished_data)\n",
    "\n",
    "print(\"Distinguished faculty added:\", len(distinguished_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "967efd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_international_adjunct_faculty():\n",
    "    url = \"https://www.daiict.ac.in/adjunct-faculty-international\"\n",
    "    res = requests.get(url, headers=HEADERS, timeout=15)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    records = []\n",
    "\n",
    "    # Each international adjunct faculty is a Drupal article\n",
    "    articles = soup.select(\"article\")\n",
    "\n",
    "    print(\"International adjunct articles found:\", len(articles))\n",
    "\n",
    "    for art in articles:\n",
    "        img = art.select_one(\"img\")\n",
    "        area = art.select_one(\".field--name-field-area-specialization\")\n",
    "\n",
    "        records.append({\n",
    "            \"faculty_type\": \"international_adjunct\",\n",
    "            \"name\": img.get(\"alt\", \"Not Available\").strip() if img else \"Not Available\",\n",
    "            \"profile_url\": \"\",\n",
    "            \"photo_url\": urljoin(BASE_URL, img[\"src\"]) if img and img.get(\"src\") else \"\",\n",
    "            \"education\": \"\",\n",
    "            \"email\": \"\",\n",
    "            \"area_specialization_short\": area.get_text(\" \", strip=True) if area else \"\",\n",
    "            \"biography\": \"\",\n",
    "            \"specialisation\": \"\",\n",
    "            \"teaching\": \"\",\n",
    "            \"research\": \"\",\n",
    "            \"publications\": \"\"\n",
    "        })\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2c51988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International adjunct articles found: 0\n",
      "Length: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "international_adjunct_data = scrape_international_adjunct_faculty()\n",
    "print(\"Length:\", len(international_adjunct_data))\n",
    "international_adjunct_data[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8d41cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International adjunct cards found: 11\n",
      "Type: <class 'list'>\n",
      "Length: 11\n",
      "Sample: [{'faculty_type': 'international_adjunct', 'name': 'Anil Maheshwari', 'profile_url': '', 'photo_url': 'https://www.daiict.ac.in/sites/default/files/faculty_image/Anil_Maheshwari.jpg', 'education': '', 'email': '', 'area_specialization_short': 'Design, Analysis and Implementation of Algorithms for Problems arising in Computational Geometry, Graph Theory, Discrete Mathematics, and Data Science.', 'biography': '', 'specialisation': '', 'teaching': '', 'research': '', 'publications': ''}]\n"
     ]
    }
   ],
   "source": [
    "international_adjunct_data = scrape_international_adjunct_faculty()\n",
    "\n",
    "print(\"Type:\", type(international_adjunct_data))\n",
    "print(\"Length:\", len(international_adjunct_data))\n",
    "print(\"Sample:\", international_adjunct_data[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "993a6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_professor_of_practice():\n",
    "    url = \"https://www.daiict.ac.in/professor-practice\"\n",
    "    res = requests.get(url, headers=HEADERS, timeout=15)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    records = []\n",
    "\n",
    "    cards = soup.select(\"div.facultyDetails\")\n",
    "    print(\"Professor of Practice cards found:\", len(cards))  # debug\n",
    "\n",
    "    for card in cards:\n",
    "        img = card.select_one(\".facultyPhoto img\")\n",
    "        area = card.select_one(\".areaSpecialization p\")\n",
    "\n",
    "        records.append({\n",
    "            \"faculty_type\": \"professor_of_practice\",\n",
    "            \"name\": img[\"alt\"].strip() if img and img.get(\"alt\") else \"Not Available\",\n",
    "            \"profile_url\": \"\",\n",
    "            \"photo_url\": urljoin(BASE_URL, img[\"src\"]) if img else \"\",\n",
    "            \"education\": \"\",\n",
    "            \"email\": \"\",\n",
    "            \"area_specialization_short\": area.get_text(\" \", strip=True) if area else \"\",\n",
    "            \"biography\": \"\",\n",
    "            \"specialisation\": \"\",\n",
    "            \"teaching\": \"\",\n",
    "            \"research\": \"\",\n",
    "            \"publications\": \"\"\n",
    "        })\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "758885e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor of Practice cards found: 4\n",
      "Professor of Practice added: 4\n"
     ]
    }
   ],
   "source": [
    "prof_practice_data = scrape_professor_of_practice()\n",
    "all_faculty_data.extend(prof_practice_data)\n",
    "\n",
    "print(\"Professor of Practice added:\", len(prof_practice_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86e25ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ faculty_raw.json updated\n",
      "Total records saved: 98\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"faculty_raw.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_faculty_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ faculty_raw.json updated\")\n",
    "print(\"Total records saved:\", len(all_faculty_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60e4d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 98\n",
      "Counter({'regular': 67, 'adjunct': 26, 'professor_of_practice': 4, 'distinguished': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "with open(\"faculty_raw.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Total records:\", len(data))\n",
    "print(Counter(d.get(\"faculty_type\", \"unknown\") for d in data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
